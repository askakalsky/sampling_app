# Опис роботи скрипта

Цей скрипт виконує **вибірку на основі аномалій** за допомогою **гнучкої архітектури автокодера**. Автокодер використовується для виявлення відхилень у даних на основі помилки реконструкції — чим більше помилка, тим більше запис вважається аномальним.

## Як працює автокодер:

### Основи автокодера:
- **Автокодер** — це тип нейронної мережі, який навчається стискати (кодувати) вхідні дані в менший простір (бутильковий шар) і потім відновлювати їх назад (декодувати). Мета автокодера — навчитися відновлювати вихідні дані якомога точніше.
- **Гнучкий автокодер** складається з двох шарів: **кодера** і **декодера**. Кодер стискає вхідні дані через прихований шар до бутилькового шару, а декодер розширює їх назад до вихідного розміру.
- Для виявлення аномалій автокодер використовується так: аномальні записи зазвичай мають більші помилки реконструкції, оскільки модель не може точно відновити ці дані, що не відповідають "звичним" паттернам.

### Як це працює:

### Підготовка даних:
- Оригінальні та попередньо оброблені набори даних перетворюються у тензори **PyTorch** для обробки автокодером.
- Дані передаються через **DataLoader** для пакетної обробки під час навчання.

### Архітектура гнучкого автокодера:
- Модель автокодера складається з двох етапів: **кодер** (стискає дані до бутилькового шару) і **декодер** (відновлює дані назад до початкового розміру).
- Використовуються шари **LeakyReLU** як функції активації для покращення навчання моделі, а також **Xavier** ініціалізація ваг.

### Навчання моделі:
- Модель тренується на основі попередньо оброблених даних протягом кількох епох із використанням **Adam**-оптимізатора та **MSELoss** для мінімізації помилки реконструкції.
- Після кожної епохи розраховується і виводиться середня втрата для оцінки прогресу.

### Виявлення аномалій:
- Після навчання автокодер використовує помилку реконструкції для кожного запису як **оцінку аномалії**. Записи з найбільшими помилками реконструкції вважаються найбільш аномальними.
- Всі записи сортуються за оцінкою аномалії, і вибираються записи з найвищими оцінками для створення вибірки.

### Формування вибірки:
- Оригінальні та попередньо оброблені набори даних отримують додаткові стовпці для збереження оцінок аномалій та міток вибірки.
- Відібрані аномальні записи додаються до фінальної вибірки.

### Звіт про виконання:
- Формується підсумковий звіт про виконану вибірку, включаючи архітектуру автокодера, розмір вибірки, кількість оброблених записів та випадкове зерно для відтворюваності.

---

## Важливі моменти:

- **Гнучка архітектура**: Автокодер має бутильковий шар для стиснення даних і декодер для відновлення. Це дозволяє зменшити розмірність і виявити важливі патерни.
- **Виявлення аномалій**: Записи з високою помилкою реконструкції вважаються аномальними, оскільки модель не змогла їх точно відновити.
- **Відтворюваність**: Використання випадкового зерна дозволяє отримувати однакові результати під час повторних запусків моделі.

---

## Можливі відхилення:

- **Параметри навчання**: Налаштування кількості епох або розміру прихованих шарів може впливати на якість виявлення аномалій.
- **Малі вибірки**: Якщо розмір вибірки занадто малий, модель може не точно відрізнити нормальні дані від аномальних.

---

## На завершення:

- **Гнучкий автокодер** — це потужний інструмент для виявлення аномалій у складних наборах даних. Він використовує помилку реконструкції для визначення аномальних записів, що дозволяє формувати вибірки на основі найбільш "незвичних" даних.
