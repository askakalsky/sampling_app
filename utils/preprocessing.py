from typing import List
import pandas as pd
from sklearn.preprocessing import StandardScaler
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def preprocess_data(df: pd.DataFrame,
                    numerical_columns: List[str],
                    categorical_columns: List[str]) -> pd.DataFrame:
    """
    Preprocesses a given DataFrame by applying one-hot encoding to categorical columns 
    and scaling numerical columns using standardization. The function returns the 
    transformed DataFrame with only the relevant processed columns.

    Args:
        df (pd.DataFrame): Input DataFrame containing raw data.
        numerical_columns (List[str]): List of column names that contain numerical data to be scaled.
        categorical_columns (List[str]): List of column names that contain categorical data for one-hot encoding.

    Returns:
        pd.DataFrame: Processed DataFrame with scaled numerical columns and one-hot encoded categorical columns.

    Raises:
        ValueError: If the input DataFrame or column lists are invalid.
    """
    try:
        # Make a copy of the DataFrame to avoid modifying the original
        df_processed = df.copy()

        # Capture the initial set of columns before one-hot encoding
        initial_columns = set(df_processed.columns)

        # Apply one-hot encoding to categorical columns
        df_processed = pd.get_dummies(
            df_processed, columns=categorical_columns)

        # Identify the new columns generated by one-hot encoding
        new_categorical_columns = list(
            set(df_processed.columns) - initial_columns)

        # Convert boolean columns to integers (0/1) for consistency
        df_processed = df_processed.astype(
            {col: 'int' for col in df_processed.columns if df_processed[col].dtype == 'bool'})

        # Standardize numerical columns
        scaler = StandardScaler()
        df_processed[numerical_columns] = scaler.fit_transform(
            df_processed[numerical_columns])

        # Combine numerical and new categorical columns for the final list of features
        available_features = numerical_columns + new_categorical_columns

        # Filter the DataFrame to include only the available features
        df_processed = df_processed[available_features]

        # Return the processed DataFrame
        return df_processed

    except Exception as e:
        # Log the exception and raise it as a ValueError
        logger.exception(f"Error in preprocess_data: {e}")
        raise ValueError(f"Data preprocessing failed: {e}")
