from typing import List
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from scipy.stats import skew
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def preprocess_data(df: pd.DataFrame,
                    numerical_columns: List[str],
                    categorical_columns: List[str],
                    sample_fraction: float = 1.0,
                    skew_threshold: float = 0.75) -> pd.DataFrame:
    """
    Preprocesses a given DataFrame by applying one-hot encoding to categorical columns 
    and scaling numerical columns. Log transformation is applied to numerical columns 
    with a skewness higher than the skew_threshold. Other numerical columns are standardized.

    Args:
        df (pd.DataFrame): Input DataFrame containing raw data.
        numerical_columns (List[str]): List of column names that contain numerical data to be scaled.
        categorical_columns (List[str]): List of column names that contain categorical data for one-hot encoding.
        sample_fraction (float, optional): Fraction of the dataset to use (default is 1.0, meaning no subsampling).
        skew_threshold (float, optional): Threshold for skewness to apply log transformation (default is 0.75).

    Returns:
        pd.DataFrame: Processed DataFrame with scaled numerical columns and one-hot encoded categorical columns.

    Raises:
        ValueError: If the input DataFrame or column lists are invalid.
    """
    try:
        # Make a copy of the DataFrame to avoid modifying the original
        df_processed = df.copy()

        # Apply sampling if necessary
        if sample_fraction < 1.0:
            df_processed = df_processed.sample(
                frac=sample_fraction, random_state=123)
            logger.info(f"Sampled {sample_fraction * 100}% of the data.")

        # Capture the initial set of columns before one-hot encoding
        initial_columns = set(df_processed.columns)

        # Apply one-hot encoding to categorical columns
        if categorical_columns:
            df_processed = pd.get_dummies(
                df_processed, columns=categorical_columns)
            logger.info(
                f"Applied one-hot encoding to categorical columns: {categorical_columns}")

        # Identify the new columns generated by one-hot encoding
        new_categorical_columns = list(
            set(df_processed.columns) - initial_columns)

        # Process numerical columns
        skewed_features = []
        normal_features = []

        for col in numerical_columns:
            # Calculate skewness of the column
            skewness = skew(df_processed[col].dropna())
            logger.info(f"Skewness for {col}: {skewness}")

            if abs(skewness) > skew_threshold:
                # Apply log transformation to highly skewed data
                df_processed[col] = df_processed[col].apply(
                    lambda x: np.log1p(x) if x > 0 else x)
                skewed_features.append(col)
            else:
                # Standardize normally distributed data
                normal_features.append(col)

        # Apply Min-Max scaling for log-transformed (skewed) columns
        if skewed_features:
            scaler = MinMaxScaler()
            df_processed[skewed_features] = scaler.fit_transform(
                df_processed[skewed_features])
            logger.info(
                f"Min-Max scaling applied to skewed features: {skewed_features}")

        # Apply Standard scaling for normal-distributed columns
        if normal_features:
            scaler = StandardScaler()
            df_processed[normal_features] = scaler.fit_transform(
                df_processed[normal_features])
            logger.info(
                f"Standard scaling applied to normally distributed features: {normal_features}")

        # Combine numerical and new categorical columns for the final list of features
        available_features = numerical_columns + new_categorical_columns

        # Filter the DataFrame to include only the available features
        df_processed = df_processed[available_features]

        # Return the processed DataFrame
        return df_processed

    except Exception as e:
        # Log the exception and raise it as a ValueError
        logger.exception(f"Error in preprocess_data: {e}")
        raise ValueError(f"Data preprocessing failed: {e}")
